{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "np.random.seed(0)\n",
    "x = ortho_group.rvs(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "std_list = [1.5, 2.0, 1.5, 2.5, 1.7, 2.2]\n",
    "fdf = pd.DataFrame()\n",
    "for i in range(6):\n",
    "    fdf[i] = np.random.normal(loc=0.0, scale=std_list[i], size=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47669462  0.15964814 -0.47766656  0.55284255 -0.13930486  0.44053222]\n",
      "[ 0.10813329 -0.8838343   0.06718921  0.39309219  0.13141423 -0.1756091 ]\n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fdf[\"group\"] = 0.9 / (1.0 + np.exp(-np.matmul(fdf.values, x[0].T) + 5.0)) +\\\n",
    "               0.1 / (1.0 + np.exp(-np.matmul(fdf.values, x[1].T) + 6.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fdf[\"prob\"] = np.random.uniform(low=0.0, high=1.0, size=200000)\n",
    "fdf[\"label\"] = fdf[\"group\"] > fdf[\"prob\"]\n",
    "fdf[\"label\"] = fdf[\"label\"] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    193807\n",
       "1      6193\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.98042789 -2.6599224  -0.83970261 -2.57846232  1.63102901  1.59680702]\n",
      " [ 1.2966543   2.77730202 -1.56281536  1.36191519  0.05851903 -1.14529369]\n",
      " [-1.11324753 -0.49798981 -1.41736499 -3.64590948 -1.74408025 -1.02271377]\n",
      " ...\n",
      " [ 0.30299166 -0.01513392 -3.76087816 -0.14516751  0.5472197  -0.88503424]\n",
      " [ 3.04884549  1.75243167  1.27937792  0.27073633  1.28851553  2.2701542 ]\n",
      " [-1.57838013 -0.60305905  0.8499289   3.59296108  0.56226344  0.36216961]]\n"
     ]
    }
   ],
   "source": [
    "cdf = fdf.copy()\n",
    "Y = cdf.label.values\n",
    "X = cdf.drop([\"prob\", \"label\", \"group\"], axis=1).values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a22ae7cd0>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ImbalancedDatasetSampler(Data.sampler.Sampler):\n",
    "    def __init__(self, dataset, indices=None, num_samples=None):\n",
    "        self.indices = list(range(len(dataset))) if indices is None else indices\n",
    "        self.num_samples = len(self.indices) if num_samples is None else num_samples\n",
    "        \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "        \n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)] for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "    \n",
    "    def _get_label(self, dataset, idx):\n",
    "        return dataset[idx][1].item()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SubNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SubNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 10)\n",
    "        self.fc2 = nn.Linear(10, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FrontProcessing(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FrontProcessing, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.zeros(6, 2))\n",
    "        self.weightT = torch.transpose(self.weight, 0, 1)\n",
    "        nn.init.orthogonal_(self.weightT)\n",
    "        self.weight.data.copy_(torch.transpose(self.weightT, 0, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.mm(x, self.weight)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, FrontProcessing, SubNet):\n",
    "        super(Net, self).__init__()\n",
    "        self.front = FrontProcessing()\n",
    "        self.subnet1 = SubNet()\n",
    "        self.subnet2 = SubNet()\n",
    "        self.oweight = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.front(x)\n",
    "        x1 = x[:, 0].view(-1, 1)\n",
    "        x2 = x[:, 1].view(-1, 1)\n",
    "        \n",
    "        x1 = self.subnet1(x1)\n",
    "        x2 = self.subnet2(x2)\n",
    "        x = self.oweight * x1 + (1.0 - self.oweight) * x2\n",
    "        return x[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (front): FrontProcessing()\n",
      "  (subnet1): SubNet(\n",
      "    (fc1): Linear(in_features=1, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      "  (subnet2): SubNet(\n",
      "    (fc1): Linear(in_features=1, out_features=10, bias=True)\n",
      "    (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net(FrontProcessing, SubNet)\n",
    "net.double()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_torch = torch.DoubleTensor(X)\n",
    "Y_torch = torch.DoubleTensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch_data_set = Data.TensorDataset(X_torch, Y_torch)\n",
    "# sampler = ImbalancedDatasetSampler(torch_data_set)\n",
    "loader = Data.DataLoader(dataset=torch_data_set, batch_size=10000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4706, 0.3566, 0.3492,  ..., 0.4136, 0.3506, 0.5655],\n",
       "       dtype=torch.float64, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.4719,  0.0804],\n",
       "         [-0.0899,  0.7272],\n",
       "         [-0.6672, -0.2345],\n",
       "         [ 0.1741, -0.4185],\n",
       "         [-0.3321, -0.3104],\n",
       "         [-0.4283,  0.3719]], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
       " tensor([[-0.1612],\n",
       "         [ 0.1058],\n",
       "         [ 0.9055],\n",
       "         [-0.9277],\n",
       "         [-0.6295],\n",
       "         [-0.2532],\n",
       "         [-0.3898],\n",
       "         [ 0.8640],\n",
       "         [-0.6482],\n",
       "         [-0.4603]], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
       " tensor([-0.6986, -0.9366, -0.5837,  0.8596,  0.4462,  0.4847,  0.0526, -0.5127,\n",
       "          0.1692, -0.9337], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
       " tensor([[-0.2285, -0.1630,  0.1995,  0.1854, -0.1402, -0.0114,  0.2022,  0.3144,\n",
       "           0.1255,  0.0427],\n",
       "         [ 0.2120, -0.1862,  0.0589, -0.2452, -0.2192, -0.1634,  0.1431,  0.1272,\n",
       "          -0.1873,  0.0955]], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
       " tensor([ 0.1736, -0.0399], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.0382],\n",
       "         [ 0.2317],\n",
       "         [ 0.6204],\n",
       "         [ 0.9602],\n",
       "         [-0.7706],\n",
       "         [-0.3665],\n",
       "         [ 0.3930],\n",
       "         [ 0.8285],\n",
       "         [ 0.8702],\n",
       "         [ 0.8824]], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
       " tensor([ 0.1990, -0.8696,  0.0920, -0.6256, -0.9320,  0.8885,  0.7604, -0.9975,\n",
       "          0.1872, -0.1685], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
       " tensor([[-0.0520, -0.1448,  0.1216, -0.1873,  0.1159,  0.1599,  0.2264,  0.1182,\n",
       "          -0.3130, -0.2051],\n",
       "         [ 0.1579,  0.0662, -0.2467, -0.1821,  0.2975,  0.2131, -0.1379, -0.0796,\n",
       "          -0.3012, -0.0057]], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
       " tensor([-0.2381, -0.2439], dtype=torch.float64, requires_grad=True)]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD([{'params': net.subnet1.parameters()}, \n",
    "                             {'params': net.subnet2.parameters()}], lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.1\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    dampening: 0\n",
       "    lr: 0.1\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | loss:  0.09846804762434078\n",
      "Parameter containing:\n",
      "tensor([[ 0.4688, -0.1700],\n",
      "        [ 0.1619,  0.8120],\n",
      "        [-0.4934, -0.2367],\n",
      "        [ 0.5393, -0.4604],\n",
      "        [-0.1496, -0.1697],\n",
      "        [ 0.4442,  0.1223]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8455], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  1 | loss:  0.09846489946310931\n",
      "Parameter containing:\n",
      "tensor([[ 0.4683, -0.1693],\n",
      "        [ 0.1612,  0.8122],\n",
      "        [-0.4930, -0.2374],\n",
      "        [ 0.5409, -0.4597],\n",
      "        [-0.1497, -0.1699],\n",
      "        [ 0.4435,  0.1230]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8450], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  2 | loss:  0.09846340850763884\n",
      "Parameter containing:\n",
      "tensor([[ 0.4679, -0.1687],\n",
      "        [ 0.1606,  0.8123],\n",
      "        [-0.4927, -0.2379],\n",
      "        [ 0.5421, -0.4592],\n",
      "        [-0.1498, -0.1700],\n",
      "        [ 0.4430,  0.1235]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8446], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  3 | loss:  0.09846232173041343\n",
      "Parameter containing:\n",
      "tensor([[ 0.4675, -0.1683],\n",
      "        [ 0.1601,  0.8125],\n",
      "        [-0.4923, -0.2384],\n",
      "        [ 0.5431, -0.4587],\n",
      "        [-0.1499, -0.1701],\n",
      "        [ 0.4427,  0.1239]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8444], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  4 | loss:  0.09846201578043319\n",
      "Parameter containing:\n",
      "tensor([[ 0.4673, -0.1679],\n",
      "        [ 0.1596,  0.8126],\n",
      "        [-0.4922, -0.2387],\n",
      "        [ 0.5438, -0.4584],\n",
      "        [-0.1500, -0.1702],\n",
      "        [ 0.4424,  0.1242]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8439], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  5 | loss:  0.09846191553144477\n",
      "Parameter containing:\n",
      "tensor([[ 0.4671, -0.1676],\n",
      "        [ 0.1593,  0.8127],\n",
      "        [-0.4921, -0.2390],\n",
      "        [ 0.5443, -0.4581],\n",
      "        [-0.1501, -0.1703],\n",
      "        [ 0.4421,  0.1245]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8437], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  6 | loss:  0.09846117971542696\n",
      "Parameter containing:\n",
      "tensor([[ 0.4668, -0.1674],\n",
      "        [ 0.1591,  0.8127],\n",
      "        [-0.4919, -0.2393],\n",
      "        [ 0.5450, -0.4579],\n",
      "        [-0.1501, -0.1704],\n",
      "        [ 0.4419,  0.1247]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8438], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  7 | loss:  0.0984611457549106\n",
      "Parameter containing:\n",
      "tensor([[ 0.4666, -0.1673],\n",
      "        [ 0.1589,  0.8127],\n",
      "        [-0.4918, -0.2394],\n",
      "        [ 0.5451, -0.4578],\n",
      "        [-0.1502, -0.1704],\n",
      "        [ 0.4421,  0.1248]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8437], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  8 | loss:  0.09846119695436782\n",
      "Parameter containing:\n",
      "tensor([[ 0.4663, -0.1671],\n",
      "        [ 0.1587,  0.8128],\n",
      "        [-0.4916, -0.2395],\n",
      "        [ 0.5455, -0.4576],\n",
      "        [-0.1502, -0.1704],\n",
      "        [ 0.4421,  0.1250]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8438], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  9 | loss:  0.09846115795943775\n",
      "Parameter containing:\n",
      "tensor([[ 0.4662, -0.1670],\n",
      "        [ 0.1585,  0.8128],\n",
      "        [-0.4915, -0.2396],\n",
      "        [ 0.5457, -0.4575],\n",
      "        [-0.1503, -0.1704],\n",
      "        [ 0.4422,  0.1251]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8438], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  10 | loss:  0.09846110711750611\n",
      "Parameter containing:\n",
      "tensor([[ 0.4661, -0.1670],\n",
      "        [ 0.1585,  0.8128],\n",
      "        [-0.4915, -0.2397],\n",
      "        [ 0.5458, -0.4575],\n",
      "        [-0.1503, -0.1704],\n",
      "        [ 0.4423,  0.1251]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8438], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  11 | loss:  0.09846123717861546\n",
      "Parameter containing:\n",
      "tensor([[ 0.4662, -0.1670],\n",
      "        [ 0.1584,  0.8128],\n",
      "        [-0.4916, -0.2397],\n",
      "        [ 0.5457, -0.4575],\n",
      "        [-0.1504, -0.1704],\n",
      "        [ 0.4421,  0.1251]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8434], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  12 | loss:  0.09846095054287768\n",
      "Parameter containing:\n",
      "tensor([[ 0.4660, -0.1670],\n",
      "        [ 0.1584,  0.8128],\n",
      "        [-0.4915, -0.2397],\n",
      "        [ 0.5459, -0.4575],\n",
      "        [-0.1503, -0.1704],\n",
      "        [ 0.4422,  0.1251]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8435], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  13 | loss:  0.0984609380548296\n",
      "Parameter containing:\n",
      "tensor([[ 0.4658, -0.1669],\n",
      "        [ 0.1583,  0.8128],\n",
      "        [-0.4914, -0.2398],\n",
      "        [ 0.5462, -0.4574],\n",
      "        [-0.1504, -0.1704],\n",
      "        [ 0.4422,  0.1252]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8437], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  14 | loss:  0.0984608947818749\n",
      "Parameter containing:\n",
      "tensor([[ 0.4658, -0.1668],\n",
      "        [ 0.1583,  0.8129],\n",
      "        [-0.4914, -0.2399],\n",
      "        [ 0.5463, -0.4573],\n",
      "        [-0.1504, -0.1705],\n",
      "        [ 0.4422,  0.1252]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8437], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  15 | loss:  0.0984608484621354\n",
      "Parameter containing:\n",
      "tensor([[ 0.4657, -0.1668],\n",
      "        [ 0.1581,  0.8129],\n",
      "        [-0.4914, -0.2400],\n",
      "        [ 0.5464, -0.4572],\n",
      "        [-0.1504, -0.1705],\n",
      "        [ 0.4421,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8435], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  16 | loss:  0.09846158455265262\n",
      "Parameter containing:\n",
      "tensor([[ 0.4655, -0.1667],\n",
      "        [ 0.1581,  0.8129],\n",
      "        [-0.4912, -0.2401],\n",
      "        [ 0.5467, -0.4572],\n",
      "        [-0.1505, -0.1705],\n",
      "        [ 0.4422,  0.1254]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8440], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  17 | loss:  0.09846329170990699\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1666],\n",
      "        [ 0.1581,  0.8129],\n",
      "        [-0.4910, -0.2402],\n",
      "        [ 0.5471, -0.4571],\n",
      "        [-0.1504, -0.1705],\n",
      "        [ 0.4422,  0.1255]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8442], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  18 | loss:  0.09846087078527922\n",
      "Parameter containing:\n",
      "tensor([[ 0.4655, -0.1667],\n",
      "        [ 0.1580,  0.8129],\n",
      "        [-0.4913, -0.2401],\n",
      "        [ 0.5467, -0.4571],\n",
      "        [-0.1505, -0.1705],\n",
      "        [ 0.4421,  0.1254]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8437], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  19 | loss:  0.09846083331517028\n",
      "Parameter containing:\n",
      "tensor([[ 0.4655, -0.1667],\n",
      "        [ 0.1581,  0.8129],\n",
      "        [-0.4913, -0.2401],\n",
      "        [ 0.5466, -0.4572],\n",
      "        [-0.1505, -0.1705],\n",
      "        [ 0.4422,  0.1254]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8437], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  20 | loss:  0.09846095650269926\n",
      "Parameter containing:\n",
      "tensor([[ 0.4655, -0.1667],\n",
      "        [ 0.1581,  0.8129],\n",
      "        [-0.4912, -0.2401],\n",
      "        [ 0.5466, -0.4572],\n",
      "        [-0.1505, -0.1705],\n",
      "        [ 0.4422,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8439], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  21 | loss:  0.09846082112551416\n",
      "Parameter containing:\n",
      "tensor([[ 0.4655, -0.1668],\n",
      "        [ 0.1582,  0.8129],\n",
      "        [-0.4913, -0.2400],\n",
      "        [ 0.5466, -0.4573],\n",
      "        [-0.1506, -0.1704],\n",
      "        [ 0.4421,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8439], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  22 | loss:  0.09846132630602275\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1668],\n",
      "        [ 0.1582,  0.8129],\n",
      "        [-0.4912, -0.2401],\n",
      "        [ 0.5468, -0.4573],\n",
      "        [-0.1507, -0.1704],\n",
      "        [ 0.4422,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8442], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  23 | loss:  0.09846080228350852\n",
      "Parameter containing:\n",
      "tensor([[ 0.4655, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4913, -0.2400],\n",
      "        [ 0.5466, -0.4573],\n",
      "        [-0.1507, -0.1704],\n",
      "        [ 0.4422,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8439], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  24 | loss:  0.09846080313316422\n",
      "Parameter containing:\n",
      "tensor([[ 0.4655, -0.1669],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4913, -0.2400],\n",
      "        [ 0.5464, -0.4574],\n",
      "        [-0.1508, -0.1704],\n",
      "        [ 0.4423,  0.1252]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8439], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  25 | loss:  0.09846118807156676\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4912, -0.2400],\n",
      "        [ 0.5465, -0.4574],\n",
      "        [-0.1508, -0.1704],\n",
      "        [ 0.4425,  0.1252]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8442], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  26 | loss:  0.0984613345247887\n",
      "Parameter containing:\n",
      "tensor([[ 0.4656, -0.1669],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4915, -0.2399],\n",
      "        [ 0.5461, -0.4575],\n",
      "        [-0.1508, -0.1704],\n",
      "        [ 0.4423,  0.1251]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8437], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  27 | loss:  0.0984607832275793\n",
      "Parameter containing:\n",
      "tensor([[ 0.4654, -0.1669],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4913, -0.2400],\n",
      "        [ 0.5464, -0.4574],\n",
      "        [-0.1507, -0.1704],\n",
      "        [ 0.4425,  0.1252]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8440], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  28 | loss:  0.09846080051838198\n",
      "Parameter containing:\n",
      "tensor([[ 0.4654, -0.1669],\n",
      "        [ 0.1583,  0.8128],\n",
      "        [-0.4913, -0.2399],\n",
      "        [ 0.5463, -0.4574],\n",
      "        [-0.1507, -0.1704],\n",
      "        [ 0.4425,  0.1252]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8440], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  29 | loss:  0.09846125895777207\n",
      "Parameter containing:\n",
      "tensor([[ 0.4655, -0.1668],\n",
      "        [ 0.1581,  0.8128],\n",
      "        [-0.4914, -0.2400],\n",
      "        [ 0.5463, -0.4574],\n",
      "        [-0.1507, -0.1704],\n",
      "        [ 0.4423,  0.1252]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8437], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  30 | loss:  0.09846085261100292\n",
      "Parameter containing:\n",
      "tensor([[ 0.4654, -0.1668],\n",
      "        [ 0.1581,  0.8128],\n",
      "        [-0.4913, -0.2401],\n",
      "        [ 0.5465, -0.4573],\n",
      "        [-0.1506, -0.1704],\n",
      "        [ 0.4424,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8439], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  31 | loss:  0.09846078926164877\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1668],\n",
      "        [ 0.1581,  0.8128],\n",
      "        [-0.4912, -0.2401],\n",
      "        [ 0.5466, -0.4573],\n",
      "        [-0.1506, -0.1704],\n",
      "        [ 0.4425,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8439], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  32 | loss:  0.09846092131373\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1668],\n",
      "        [ 0.1581,  0.8128],\n",
      "        [-0.4913, -0.2401],\n",
      "        [ 0.5466, -0.4573],\n",
      "        [-0.1506, -0.1704],\n",
      "        [ 0.4423,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8438], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  33 | loss:  0.09846073641003569\n",
      "Parameter containing:\n",
      "tensor([[ 0.4652, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4912, -0.2401],\n",
      "        [ 0.5467, -0.4573],\n",
      "        [-0.1506, -0.1704],\n",
      "        [ 0.4423,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8440], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  34 | loss:  0.09846087123154168\n",
      "Parameter containing:\n",
      "tensor([[ 0.4651, -0.1667],\n",
      "        [ 0.1581,  0.8128],\n",
      "        [-0.4911, -0.2402],\n",
      "        [ 0.5469, -0.4573],\n",
      "        [-0.1506, -0.1704],\n",
      "        [ 0.4423,  0.1254]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8442], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  35 | loss:  0.09846087116972951\n",
      "Parameter containing:\n",
      "tensor([[ 0.4654, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4913, -0.2401],\n",
      "        [ 0.5465, -0.4574],\n",
      "        [-0.1506, -0.1703],\n",
      "        [ 0.4423,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8440], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  36 | loss:  0.09846072030610291\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4913, -0.2402],\n",
      "        [ 0.5467, -0.4573],\n",
      "        [-0.1507, -0.1704],\n",
      "        [ 0.4422,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8441], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  37 | loss:  0.09846088251094172\n",
      "Parameter containing:\n",
      "tensor([[ 0.4654, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4914, -0.2401],\n",
      "        [ 0.5466, -0.4574],\n",
      "        [-0.1507, -0.1703],\n",
      "        [ 0.4421,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8440], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  38 | loss:  0.09846111354727984\n",
      "Parameter containing:\n",
      "tensor([[ 0.4651, -0.1668],\n",
      "        [ 0.1583,  0.8128],\n",
      "        [-0.4911, -0.2402],\n",
      "        [ 0.5469, -0.4573],\n",
      "        [-0.1507, -0.1703],\n",
      "        [ 0.4423,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8445], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  39 | loss:  0.09846070741972118\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1669],\n",
      "        [ 0.1583,  0.8128],\n",
      "        [-0.4913, -0.2401],\n",
      "        [ 0.5466, -0.4574],\n",
      "        [-0.1508, -0.1703],\n",
      "        [ 0.4423,  0.1252]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8443], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  40 | loss:  0.09846087056558277\n",
      "Parameter containing:\n",
      "tensor([[ 0.4652, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4912, -0.2401],\n",
      "        [ 0.5467, -0.4574],\n",
      "        [-0.1507, -0.1703],\n",
      "        [ 0.4424,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8445], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  41 | loss:  0.09846131144483658\n",
      "Parameter containing:\n",
      "tensor([[ 0.4655, -0.1669],\n",
      "        [ 0.1582,  0.8127],\n",
      "        [-0.4914, -0.2401],\n",
      "        [ 0.5463, -0.4575],\n",
      "        [-0.1508, -0.1703],\n",
      "        [ 0.4423,  0.1252]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8440], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  42 | loss:  0.09846072009511524\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4913, -0.2401],\n",
      "        [ 0.5465, -0.4574],\n",
      "        [-0.1508, -0.1703],\n",
      "        [ 0.4424,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8443], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  43 | loss:  0.09846081646713166\n",
      "Parameter containing:\n",
      "tensor([[ 0.4654, -0.1668],\n",
      "        [ 0.1580,  0.8128],\n",
      "        [-0.4913, -0.2402],\n",
      "        [ 0.5465, -0.4573],\n",
      "        [-0.1509, -0.1703],\n",
      "        [ 0.4423,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8442], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  44 | loss:  0.09846082110483723\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4911, -0.2402],\n",
      "        [ 0.5467, -0.4574],\n",
      "        [-0.1508, -0.1703],\n",
      "        [ 0.4424,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8445], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  45 | loss:  0.09846070628420657\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4911, -0.2401],\n",
      "        [ 0.5466, -0.4574],\n",
      "        [-0.1508, -0.1703],\n",
      "        [ 0.4425,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8444], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  46 | loss:  0.09846068527494058\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1668],\n",
      "        [ 0.1581,  0.8128],\n",
      "        [-0.4911, -0.2402],\n",
      "        [ 0.5466, -0.4574],\n",
      "        [-0.1509, -0.1703],\n",
      "        [ 0.4424,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8444], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  47 | loss:  0.09846067971262752\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1668],\n",
      "        [ 0.1581,  0.8128],\n",
      "        [-0.4911, -0.2402],\n",
      "        [ 0.5467, -0.4573],\n",
      "        [-0.1509, -0.1703],\n",
      "        [ 0.4423,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8443], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  48 | loss:  0.09846108595242851\n",
      "Parameter containing:\n",
      "tensor([[ 0.4654, -0.1668],\n",
      "        [ 0.1581,  0.8128],\n",
      "        [-0.4912, -0.2402],\n",
      "        [ 0.5465, -0.4574],\n",
      "        [-0.1509, -0.1703],\n",
      "        [ 0.4423,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8440], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  49 | loss:  0.09846069508848503\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1667],\n",
      "        [ 0.1580,  0.8128],\n",
      "        [-0.4911, -0.2403],\n",
      "        [ 0.5468, -0.4573],\n",
      "        [-0.1508, -0.1703],\n",
      "        [ 0.4423,  0.1254]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8444], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  50 | loss:  0.09846096140153755\n",
      "Parameter containing:\n",
      "tensor([[ 0.4652, -0.1667],\n",
      "        [ 0.1580,  0.8128],\n",
      "        [-0.4910, -0.2403],\n",
      "        [ 0.5469, -0.4573],\n",
      "        [-0.1508, -0.1703],\n",
      "        [ 0.4424,  0.1254]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8445], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  51 | loss:  0.09846069003354051\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1668],\n",
      "        [ 0.1581,  0.8128],\n",
      "        [-0.4912, -0.2403],\n",
      "        [ 0.5467, -0.4573],\n",
      "        [-0.1508, -0.1703],\n",
      "        [ 0.4422,  0.1254]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8442], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  52 | loss:  0.09846104687822316\n",
      "Parameter containing:\n",
      "tensor([[ 0.4654, -0.1668],\n",
      "        [ 0.1580,  0.8128],\n",
      "        [-0.4912, -0.2402],\n",
      "        [ 0.5466, -0.4573],\n",
      "        [-0.1508, -0.1703],\n",
      "        [ 0.4422,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8441], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  53 | loss:  0.09846117241690121\n",
      "Parameter containing:\n",
      "tensor([[ 0.4651, -0.1667],\n",
      "        [ 0.1581,  0.8128],\n",
      "        [-0.4909, -0.2403],\n",
      "        [ 0.5470, -0.4572],\n",
      "        [-0.1508, -0.1703],\n",
      "        [ 0.4424,  0.1254]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8446], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  54 | loss:  0.09846074052298757\n",
      "Parameter containing:\n",
      "tensor([[ 0.4652, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4910, -0.2403],\n",
      "        [ 0.5469, -0.4573],\n",
      "        [-0.1508, -0.1703],\n",
      "        [ 0.4424,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8445], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  55 | loss:  0.09846096524372455\n",
      "Parameter containing:\n",
      "tensor([[ 0.4654, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4913, -0.2402],\n",
      "        [ 0.5466, -0.4574],\n",
      "        [-0.1507, -0.1703],\n",
      "        [ 0.4423,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8442], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n",
      "Epoch:  56 | loss:  0.09846085285581913\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653, -0.1668],\n",
      "        [ 0.1582,  0.8128],\n",
      "        [-0.4913, -0.2402],\n",
      "        [ 0.5466, -0.4574],\n",
      "        [-0.1507, -0.1703],\n",
      "        [ 0.4423,  0.1253]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8443], dtype=torch.float64, requires_grad=True)\n",
      "##########################\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(600):\n",
    "    for step, (X_train, Y_train) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        net.zero_grad()\n",
    "        X_train = X_train.requires_grad_(True)\n",
    "        \n",
    "        prediction = net(X_train)\n",
    "        loss = criterion(prediction, Y_train.double())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        weight_partial = net.front.weight.grad\n",
    "        oweight_partial = net.oweight.grad\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            matA = torch.mm(weight_partial, \n",
    "                            torch.transpose(net.front.weight, 0, 1)) - torch.mm(net.front.weight, \n",
    "                                                                          torch.transpose(weight_partial, 0, 1))\n",
    "            update_matrix = torch.mm(torch.inverse(torch.eye(6).double() + matA * lr / 2.0), (torch.eye(6).double() - matA * lr / 2.0))\n",
    "            updated_weight = torch.mm(update_matrix, net.front.weight)\n",
    "            updated_oweight = net.oweight - lr * oweight_partial\n",
    "            \n",
    "            net.front.weight.data.copy_(updated_weight)\n",
    "            net.oweight.data.copy_(updated_oweight)\n",
    "            net.oweight.clamp_(0, 1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        loss_all = criterion(net(X_torch), Y_torch.double())\n",
    "        print(\"Epoch: \", epoch, \"| loss: \", loss_all.data.numpy())\n",
    "        print(net.front.weight)\n",
    "        print(net.oweight)\n",
    "        print(\"##########################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47669462,  0.15964814, -0.47766656,  0.55284255, -0.13930486,\n",
       "        0.44053222])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10813329, -0.8838343 ,  0.06718921,  0.39309219,  0.13141423,\n",
       "       -0.1756091 ])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.8297], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4650, -0.1690],\n",
      "        [ 0.1581,  0.8144],\n",
      "        [-0.4924, -0.2387],\n",
      "        [ 0.5453, -0.4546],\n",
      "        [-0.1475, -0.1710],\n",
      "        [ 0.4441,  0.1238]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1522],\n",
      "        [ 0.1058],\n",
      "        [ 0.7251],\n",
      "        [-0.2440],\n",
      "        [-0.6087],\n",
      "        [-0.1706],\n",
      "        [-0.3767],\n",
      "        [ 0.6839],\n",
      "        [-0.5567],\n",
      "        [-0.4776]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.7005, -0.9366, -0.7670,  1.5191,  0.6499,  1.0968,  0.1035, -0.6464,\n",
      "         0.4757, -0.9273], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2282, -0.1630, -0.1215,  0.4332,  0.1388,  0.3737,  0.1821, -0.0019,\n",
      "          0.2313,  0.0155],\n",
      "        [ 0.2117, -0.1862,  0.3799, -0.4929, -0.4983, -0.5485,  0.1632,  0.4434,\n",
      "         -0.2932,  0.1227]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.0087, -0.8750], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0869],\n",
      "        [ 0.2277],\n",
      "        [ 0.7129],\n",
      "        [ 0.9631],\n",
      "        [-0.7057],\n",
      "        [ 0.2007],\n",
      "        [ 0.2155],\n",
      "        [ 0.8582],\n",
      "        [ 0.8834],\n",
      "        [ 0.8471]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1032, -0.8705,  0.3880, -0.6203, -0.9600,  1.2762,  1.3696, -0.9843,\n",
      "         0.3344, -0.1811], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 6.3930e-02, -1.4411e-01,  3.6466e-01, -6.7878e-02,  9.7690e-02,\n",
      "          9.3568e-01,  8.6296e-01,  1.7716e-01,  5.0969e-04, -3.0209e-02],\n",
      "        [ 4.1928e-02,  6.5545e-02, -4.8974e-01, -3.0152e-01,  3.1573e-01,\n",
      "         -5.6268e-01, -7.7446e-01, -1.3851e-01, -6.1473e-01, -1.8061e-01]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4853, -0.9673], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# out = net(X_torch)\n",
    "# _, prediction = torch.max(out.data, 1)\n",
    "# print('accuracy:%.3f %%' % (100 * torch.sum(Y_torch.long()==prediction) / 200000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_result_1 = net.front(X_torch)[:, 0].view(-1, 1).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result_1 = net.subnet1(net.front(X_torch)[:, 0].view(-1, 1))[:, 1].data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true_1 = np.arange(-10, 10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_1 = 1.0 / (1.0 + np.exp(-x_true_1 + 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_result_2 = net.front(X_torch)[:, 1].view(-1, 1).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_result_2 = net.subnet2(net.front(X_torch)[:, 1].view(-1, 1))[:, 1].data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true_2 = np.arange(-10, 10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_2 = 1.0 / (1.0 + np.exp(-x_true_2 + 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# reg = LinearRegression()\n",
    "# reg.fit(x_result, y_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x_result_1.reshape(-1, 1), y_result_1)\n",
    "ax.scatter(x_true_1, y_true_1)\n",
    "# ax.plot(x_result.reshape(-1, 1), reg.predict(x_result))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter((1.0 - x_result_2).reshape(-1, 1), y_result_2)\n",
    "ax.scatter(x_true_2, y_true_2)\n",
    "# ax.plot(x_result.reshape(-1, 1), reg.predict(x_result))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter((x_result_1).reshape(-1, 1), y_result_1)\n",
    "# ax.plot(x_result.reshape(-1, 1), reg.predict(x_result))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
